<div align="center">
  <img src="https://github.com/BorisKlimchenko.png" width="180">
  
  <h1>Boris Klimchenko</h1>
  
  <h3>üöÄ ML Systems Engineer | Generative AI Specialist</h3>

  <p>
    <b>Core Focus:</b><br>
    High-Performance Inference ‚Ä¢ Latent Diffusion Pipelines ‚Ä¢ Modular Software Architecture
  </p>

  <a href="https://www.youtube.com/channel/UC_wq5ASqVRPkqu_P1iTk_tA">
    <img src="https://img.shields.io/badge/YouTube-Dev_Logs-red?style=for-the-badge&logo=youtube&logoColor=white">
  </a>
</div>

<br>

### üì° Current Status
> *"The map is not the territory. The token is not the meaning."* ‚Äî Alfred Korzybski

* **Role:** Developing hardware-aware inference engines for Open Source models.
* **Objective:** Bridging the gap between experimental Research code and Production-grade engineering.
* **Active Sprint:** Implementing **Adaptive Hardware Strategy** (HAL) & **Deterministic Sampling** for Latent Diffusion pipelines.

---

### üõ†Ô∏è Engineering Stack

| **Domain** | **Stack & Instrumentation** |
| :--- | :--- |
| **Deep Learning** | ![Python](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white) ![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-EE4C2C?logo=pytorch&logoColor=white) `Diffusers` `xFormers` |
| **Generative R&D** | `AnimateDiff` ‚Ä¢ `ControlNet` ‚Ä¢ `Stable Diffusion` ‚Ä¢ `Inference Optimization` |
| **Infrastructure** | ![Linux](https://img.shields.io/badge/Linux-Bash-FCC624?logo=linux&logoColor=black) ![Docker](https://img.shields.io/badge/Docker-Container-2496ED?logo=docker&logoColor=white) `CUDA Profiling` ‚Ä¢ `Google Colab Pro` |
| **Architecture** | **OOP Patterns** ‚Ä¢ **SOLID Principles** ‚Ä¢ **Strategy Pattern** ‚Ä¢ **Clean Architecture** |

---

### üß¨ Featured Project: <a href="https://github.com/BorisKlimchenko/JEPA-Synthetic-Lab">Adaptive-Motion-Lab</a>

**Status:** v1.0 Stable (Refactored)  
**Type:** Hardware-Aware Inference Engine for AnimateDiff.  
**Engineering Challenge:** Solving the "works on my machine" problem for heavy diffusion models across heterogeneous hardware (T4 vs A100).

**Key Implementation Details:**
* **Hardware Abstraction Layer (HAL):** Runtime detection of GPU Architecture (Ampere vs Turing).
* **Strategy Pattern:** Dynamic injection of Attention mechanisms (Native SDPA vs Memory Efficient xFormers).
* **VRAM Safety:** Automatic resolution scaling and CPU-offload based on available memory.

---

<div align="center">
  <p><i>Building tools for the next generation of synthetic media.</i></p>
</div>
